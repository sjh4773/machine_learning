{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "regression_analysis.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN5S97oCE/LjQCrrJmMoZFR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sjh4773/my_machine_learning/blob/main/regression_analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inunLd_x1E0v"
      },
      "source": [
        "##Logistic regression example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WCf3WZMb0q7g"
      },
      "source": [
        "# 라이브러리 호출\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import pandas as pd # 데이터를 가공하기 위함\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt # 그림을 그리기 위함\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mPunsSY1_ZI"
      },
      "source": [
        "#파일 업로드"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYFXD--319gY"
      },
      "source": [
        "data = pd.read_csv('./mba_admission.csv') # ./ --> 현재 경로를 나타낸다"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7nApolh38FN"
      },
      "source": [
        "data.columns # 데이터 속성을 확인함"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWeprzoj4H-f"
      },
      "source": [
        "data.shape # (40,4) --> 행 : 데이터 크기, 열 : gmat, gpa, work_experience --> 입력, admitted --> 결과"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJkoIhNN4lSl"
      },
      "source": [
        "data.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4v89Dd3D2JW9"
      },
      "source": [
        "# dataset 가공\n",
        "class dataset(torch.utils.data.Dataset):\n",
        "    def __init__(self,data):\n",
        "        self.data = data\n",
        "        self.data['gmat'] /= self.data['gmat'].max() # max 함수를 통해 정규화, 모든 데이터가 0~1로 정규화 된다.\n",
        "        self.data['gpa'] /= self.data['gpa'].max()\n",
        "        self.data['work_experience'] /= self.data['work_experience'].max()\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.Tensor(self.data[self.data.columns[:3]].values) # self.data.columns[:3] --> gmat, gpa, work_experience\n",
        "        Y = torch.Tensor(self.data['admitted'])                   # .values --> pandas의 자체값만을 이용하겠다는 뜻 \n",
        "        return X[idx,:], Y[idx]\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.data.shape[0] # 전체 데이터의 개수 --> 40"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_rY7yrb68cA"
      },
      "source": [
        "train_dataset = dataset(data)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PBGA6ho7OXs"
      },
      "source": [
        "# neural network 모델 생성\n",
        "# 구조: 입력(3), 은닉(10), 출력(1)\n",
        "# 활성화:        tanh      sigmoid\n",
        "class admission_model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(admission_model,self).__init__()\n",
        "        self.lin1 = nn.Linear(3, 10)\n",
        "        self.lin2 = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self,x): # 입력받은 데이터가 일련의 과정을 거치면 리턴되는 x는 y_hat\n",
        "        x = self.lin1(x)\n",
        "        x = F.tanh(x)\n",
        "        x = self.lin2(x)\n",
        "        x = F.sigmoid(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYK-8Aqt7n_P"
      },
      "source": [
        "model = admission_model()\n",
        "optimizer = optim.SGD(model.parameters(),lr=0.5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v_b7JIhE-fpn"
      },
      "source": [
        "# 학습단계\n",
        "# 최적화를 할 때 반복횟수가 굉장히 중요하다. 어떤 데이터를 어떤 배치만큼 잘라내어 마지막 배치까지 돌아야 epoch가 됨\n",
        "for ep in range(100): # 100번 epoch\n",
        "    loss_buffer = [] #  각 epoch마다 loss를 확인하기 위함\n",
        "    for X,Y in train_loader: # epoch마다 각각의 batch 단위를 학습 # 여기에서 X,Y는 위에서 정의한 class 안의 getitem의 X,Y에 대응되는 것\n",
        "        optimizer.zero_grad()\n",
        "        y_infer = model(X) # y_infer.shape == (8,1)\n",
        "        Y = Y.view(-1,1) # Y.shape(8,) --> Y.view(-1,1)\n",
        "        loss = -torch.mean(Y*torch.log(y_infer)+(1-Y)*torch.log(1-y_infer)) # cross entropy 거리함수 이용\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        loss_buffer.append(loss.item()) # 각 배치마다 loss_buffer의 빈 array에 loss 값 추가 \n",
        "\n",
        "    if ep % 10 == 0:\n",
        "        print('Epoch : {}, Loss: {}'.format(ep, np.mean(loss_buffer)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cFqE6fttCXDW"
      },
      "source": [
        "# 결과 시각화\n",
        "y_infer = model(torch.Tensor(data[data.columns[:3]].values))\n",
        "\n",
        "plt.scatter(np.arange(data.shape[0]),data['admitted'],color='red',label='True result')\n",
        "plt.scatter(np.arange(data.shape[0]),y_infer.detach().numpy(),color='blue',label='Predicted result') # detach() : 기존 Tensor에서 gradient 전파가 안되는 텐서 생성\n",
        "plt.hlines(0.5,-10,60,label='Admission boundary')\n",
        "plt.legend(loc='upper center', fontsize='10')\n",
        "plt.xlim(-1,41)\n",
        "plt.ylim(-0.1,1.5)\n",
        "plt.xlabel('Volunteer')\n",
        "plt.ylabel('Result')\n",
        "plt.title('MBA admission result included prediction')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}